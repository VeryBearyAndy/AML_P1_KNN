{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b20994",
   "metadata": {},
   "source": [
    " Andrew J Markland, ajm259@uakron.edu\\\n",
    " The University of Akron, CEPS, School of Computer Science\\\n",
    " Applied Machine Learning CPSC-436-010\\\n",
    " Dr. Zhong-Hui Duan\\\n",
    "\n",
    "# Project 1, kNN\n",
    " -Project Scope:\\\n",
    "     Apply the machine learning classification algorithm \"k nearest neighbors\"(kNN) to correctly classify a dataset of people based on their risk for MI, Myocardial Infarction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1dda31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports, decided to keep that at the top to keep them global \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.plotting import scatter_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c631062",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgList = pd.DataFrame(columns = ['run', 'avg']).set_index('run')\n",
    "for x in range(100):\n",
    "    people_df = pd.read_csv(\"NHANES_data_train.csv\")\n",
    "    \n",
    "#partitioning random test data and and training data\n",
    "    trainDf, testDf = train_test_split(people_df, test_size = 0.2, random_state = None)\n",
    "    \n",
    "#Get counts of persons with MI and noMI\n",
    "    MIcount = (trainDf[\"MI\"] == 1).sum()\n",
    "    noMIcount = (trainDf[\"MI\"] == 2).sum()\n",
    "    testMIcount = (testDf[\"MI\"] == 1).sum()\n",
    "    testnoMIcount = (testDf[\"MI\"] == 2).sum()\n",
    "#Isolate the same number of NoMI's as the MI subgroup\n",
    "    dirtyTrainMI_sample = trainDf[trainDf[\"MI\"] == 1]\n",
    "    dirtyTrainNoMI_sample = (trainDf[trainDf[\"MI\"] == 2]).sample(frac=(MIcount/noMIcount))\n",
    "    dirtyTestMI_sample = testDf[testDf[\"MI\"] == 1]\n",
    "    dirtyTestNoMI_sample = (testDf[testDf[\"MI\"] == 2])\n",
    "\n",
    "#Declare imputer object and clean the data\n",
    "    imputer = KNNImputer(n_neighbors = 21)\n",
    "    \n",
    "    crudeCleanTrainMI = imputer.fit_transform(dirtyTrainMI_sample)\n",
    "    cleanTrainMI = pd.DataFrame(crudeCleanTrainMI, columns = dirtyTrainMI_sample.columns)\n",
    "\n",
    "    crudeCleanTrainNoMI = imputer.fit_transform(dirtyTrainNoMI_sample)\n",
    "    cleanTrainNoMI = pd.DataFrame(crudeCleanTrainNoMI, columns = dirtyTrainNoMI_sample.columns)\n",
    "\n",
    "    crudeCleanTestMI = imputer.fit_transform(dirtyTestMI_sample)\n",
    "    cleanTestMI = pd.DataFrame(crudeCleanTestMI, columns = dirtyTestMI_sample.columns)\n",
    "\n",
    "    crudeCleanTestNoMI = imputer.fit_transform(dirtyTestNoMI_sample)\n",
    "    cleanTestNoMI = pd.DataFrame(crudeCleanTestNoMI, columns = dirtyTestNoMI_sample.columns)\n",
    "    \n",
    "#fTrainSample is the final sample group to train the KNN model on, comprising the same number of\n",
    "    #people with MI's and people without MI's and on a random scale\n",
    "    fTrainSample = (pd.concat([cleanTrainMI, cleanTrainNoMI])).sample(frac=1)\n",
    "    fTestSample = (pd.concat([cleanTestMI, cleanTestNoMI])).sample(frac=1)\n",
    "    \n",
    "##---------------------------------------------------------- break in data acquisition ---------------------------------------------------------------\n",
    "    # metric='manhattan'\n",
    "    knn = KNeighborsClassifier(n_neighbors = 21, metric='manhattan')\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "#weights for scalaing attribute importance\n",
    "    # 1:ID, 2:income, 3:sex, 4:age 5:race, 6:edu, 7:dist, 8:syst, 9:pulse, 10:BMI, 11:HDL 12:trig, 13:LDL, 14:TChol, 15:Kidney, 16:diabetes, 17:smoke, \n",
    "    # 18:active, 19:insured\n",
    "    #                    1    2    3    4    5    6    7    8    9    10   11   12   13   14   15   16   17   18   19\n",
    "    weights = np.array([1.0, 1.3, 0.0, 1.3, 0.0, 0.0, 1.3, 1.3, 1.3, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0])\n",
    "\n",
    "    #clean wieghts\n",
    "#   weights = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "#Prepping the training data to train the model\n",
    "    x_train = scaler.fit_transform(fTrainSample.drop(\"MI\", axis=1)) * weights  \n",
    "    y_train = fTrainSample[\"MI\"]\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "#prepping the test data to check the model\n",
    "    x_test = scaler.transform(fTestSample.drop(\"MI\", axis=1)) * weights\n",
    "    y_test = fTestSample[\"MI\"]\n",
    "    \n",
    "#testing the model\n",
    "    predictions = knn.predict(x_test)\n",
    "    \n",
    "#logging accuracy to check the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    #print(f\"Model accuracy: {accuracy}\")\n",
    "    avgList.loc[x, 'avg'] = accuracy\n",
    "\n",
    "##------------------------------------------------------------ break in data analysis -----------------------------------------------------------------\n",
    "\n",
    "print(\"avg accuracy: \" + str(avgList['avg'].mean()) + '\\n')\n",
    "print(\"median accuracy: \" + str(avgList['avg'].median()) + '\\n')\n",
    "print(\"highest accuracy: \" + str(avgList['avg'].max()) + '\\n')\n",
    "print(\"Lowest accuracy: \" + str(avgList['avg'].min()) + '\\n')\n",
    "print(\"accuracy range: \" + str((avgList['avg'].max() - avgList['avg'].min()) * 100) + '%\\n')\n",
    "\n",
    "\n",
    "# Plotting the accuracy values\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "plt.plot(avgList.index, avgList['avg'], label='Accuracy per Run', marker='o', linestyle='-', color='blue')\n",
    "\n",
    "# Calculating the statistics\n",
    "average_accuracy = avgList['avg'].mean()\n",
    "median_accuracy = avgList['avg'].median()\n",
    "highest_accuracy = avgList['avg'].max()\n",
    "lowest_accuracy = avgList['avg'].min()\n",
    "\n",
    "# Adding lines for average, median, highest, and lowest\n",
    "plt.axhline(y=average_accuracy, color='green', linestyle='-', label=f'Average Accuracy ({average_accuracy:.2f})')\n",
    "plt.axhline(y=median_accuracy, color='orange', linestyle='-', label=f'Median Accuracy ({median_accuracy:.2f})')\n",
    "plt.axhline(y=highest_accuracy, color='purple', linestyle='-', label=f'Highest Accuracy ({highest_accuracy:.2f})')\n",
    "plt.axhline(y=lowest_accuracy, color='red', linestyle='-', label=f'Lowest Accuracy ({lowest_accuracy:.2f})')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Run')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Metrics Over 100 Runs')\n",
    "plt.xticks(range(0, 101, 5))  # Adjust x-axis ticks if necessary\n",
    "plt.grid(True)  # Adds a grid for better readability\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9cc5e-35ce-49ad-bb5f-90951ba251c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
